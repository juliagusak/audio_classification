{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Nsynth autoencoder for fine-tuning\n",
    "\n",
    "This is draft notebook to test NSynth autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/julia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/julia/DeepVoice_project/model_units.py:96: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "from model_units import *\n",
    "import librispeech_reader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, train_path = None):\n",
    "        self.num_iters = 200000\n",
    "        self.learninig_rate = 1e-3\n",
    "        self.ae_hop_length = 512\n",
    "        self.ae_bottleneck_width = 16\n",
    "        self.train_path = train_path\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        print('Get batch')\n",
    "        assert self.train_path is not None\n",
    "        data_train = librispeech_reader.LibriSpeechDataset(\n",
    "            self.train_path, is_training = True)\n",
    "        return data_train.get_wavenet_batch(batch_size, length = 39936)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _condition(x, encoding):\n",
    "        \"\"\"Condition the input on the encoding.\n",
    "        Args:\n",
    "          x: The [mb, length, channels] float tensor input.\n",
    "          encoding: The [mb, encoding_length, channels] float tensor encoding.\n",
    "        Returns:\n",
    "          The output after broadcasting the encoding to x's shape and adding them.\n",
    "        \"\"\"\n",
    "        mb, length, channels = x.get_shape().as_list()\n",
    "        enc_mb, enc_length, enc_channels = encoding.get_shape().as_list()\n",
    "        assert enc_mb == mb\n",
    "        assert enc_channels == channels\n",
    "\n",
    "        encoding = tf.reshape(encoding, [mb, enc_length, 1, channels])\n",
    "        x = tf.reshape(x, [mb, enc_length, -1, channels])\n",
    "        x += encoding\n",
    "        x = tf.reshape(x, [mb, length, channels])\n",
    "        x.set_shape([mb, length, channels])\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def build(self, inputs, is_training):\n",
    "        ''' \n",
    "        Args:\n",
    "          inputs: A dict of inputs. For training, should contain 'wav'.\n",
    "        '''\n",
    "        del is_training\n",
    "        num_stages = 10\n",
    "        num_layers = 30\n",
    "        filter_length = 3\n",
    "        width = 512\n",
    "        ae_num_stages = 10\n",
    "        ae_num_layers = 30\n",
    "        ae_filter_length = 3\n",
    "        ae_width = 128\n",
    "        skip_width = 256\n",
    "        \n",
    "        # Encode the source with 8-bit Mu-Law.\n",
    "        x = inputs['wav']\n",
    "        x_quantized = mu_law(x)\n",
    "        with tf.name_scope(\"scale_and_expand_dims\"):\n",
    "            x_scaled = tf.cast(x_quantized, tf.float32) / 128.0\n",
    "            x_scaled = tf.expand_dims(x_scaled, 2)\n",
    "            \n",
    "        \n",
    "        ###\n",
    "        # The Non-Causal Temporal Encoder.\n",
    "        ###\n",
    "        en = conv1d(x_scaled,\n",
    "                    causal=False,\n",
    "                    num_filters=ae_width,\n",
    "                    filter_length=ae_filter_length, dilation = 1,\n",
    "                    name='ae_startconv')\n",
    "\n",
    "        for num_layer in range(ae_num_layers):\n",
    "            with tf.name_scope('layer_{}'.format(num_layer)):\n",
    "                dilation = 2**(num_layer % ae_num_stages)\n",
    "\n",
    "                d = tf.nn.relu(en)\n",
    "                d = conv1d(d,\n",
    "                           causal=False,\n",
    "                           num_filters=ae_width,\n",
    "                           filter_length=ae_filter_length,\n",
    "                           dilation=dilation,\n",
    "                           name='ae_dilatedconv_%d' % (num_layer + 1))\n",
    "                d = tf.nn.relu(d)\n",
    "                en += conv1d(d,\n",
    "                             num_filters=ae_width,\n",
    "                             filter_length=1,\n",
    "                             name='ae_res_%d' % (num_layer + 1))\n",
    "\n",
    "        en = conv1d(en,\n",
    "                    num_filters=self.ae_bottleneck_width,\n",
    "                    filter_length=1,\n",
    "                    name='ae_bottleneck')\n",
    "        en = pool1d(en, self.ae_hop_length, name = 'ae_pool', mode = 'avg')\n",
    "        encoding = en\n",
    "                    \n",
    "        \n",
    "        ###\n",
    "        # Classification layers.\n",
    "        ###\n",
    "        en_shape = encoding.get_shape().as_list()\n",
    "        clf_hu_size1 = 256\n",
    "        clf_hu_size2 = 128\n",
    "        clf_output_size = 40\n",
    "        \n",
    "        clf = tf.reshape(en, [-1, en_shape[-1]*en_shape[-2]])\n",
    "        clf = fc_layer(clf,  en_shape[-1]*en_shape[-2], clf_hu_size1, \"clf_fc1\")\n",
    "        clf = tf.nn.relu(clf, name = \"clf_relu1\")\n",
    "        clf = tf.nn.dropout(clf, keep_prob = 0.5)\n",
    "        clf = fc_layer(clf,  clf_hu_size1, clf_hu_size2, \"clf_fc2\")\n",
    "        clf = tf.nn.relu(clf, name = \"clf_relu2\")\n",
    "        \n",
    "        \n",
    "             ###\n",
    "        # The WaveNet Decoder.\n",
    "        ###\n",
    "        l = shift_right(x_scaled)\n",
    "        l = conv1d(l, num_filters=width, filter_length=filter_length, name='startconv')\n",
    "\n",
    "        # Set up skip connections.\n",
    "        s = conv1d(l, num_filters=skip_width, filter_length=1, name='skip_start')\n",
    "\n",
    "        # Residual blocks with skip connections.\n",
    "        for i in range(num_layers):\n",
    "            dilation = 2**(i % num_stages)\n",
    "            d = conv1d(\n",
    "              l,\n",
    "              num_filters=2 * width,\n",
    "              filter_length=filter_length,\n",
    "              dilation=dilation,\n",
    "              name='dilatedconv_%d' % (i + 1))\n",
    "            d = self._condition(d,conv1d(\n",
    "                                  en,\n",
    "                                  num_filters=2 * width,\n",
    "                                  filter_length=1,\n",
    "                                  name='cond_map_%d' % (i + 1)))\n",
    "\n",
    "            assert d.get_shape().as_list()[2] % 2 == 0\n",
    "            m = d.get_shape().as_list()[2] // 2\n",
    "            d_sigmoid = tf.sigmoid(d[:, :, :m])\n",
    "            d_tanh = tf.tanh(d[:, :, m:])\n",
    "            d = d_sigmoid * d_tanh\n",
    "\n",
    "            l += conv1d(\n",
    "              d, num_filters=width, filter_length=1, name='res_%d' % (i + 1))\n",
    "            s += conv1d(\n",
    "              d, num_filters=skip_width, filter_length=1, name='skip_%d' % (i + 1))\n",
    "\n",
    "        s = tf.nn.relu(s)\n",
    "        s = conv1d(s, num_filters=skip_width, filter_length=1, name='out1')\n",
    "        s = self._condition(s, conv1d(\n",
    "                                en,\n",
    "                                num_filters=skip_width,\n",
    "                                filter_length=1,\n",
    "                                name='cond_map_out1'))\n",
    "        s = tf.nn.relu(s)\n",
    "\n",
    "        ###\n",
    "        # Compute the logits and get the loss for classifier.\n",
    "        ###\n",
    "        logits1 = fc_layer(clf,  clf_hu_size2, clf_output_size, \"clf_logits1\")\n",
    "        probs1 = tf.nn.softmax(logits1, name = 'clf_softmax1')\n",
    "\n",
    "#         logits2 = fc_layer(clf,  clf_hu_size2, 2, \"clf_fc2\")\n",
    "#         probs2 = tf.nn.softmax(logits2, name = 'clf_softmax2')\n",
    "\n",
    "     \n",
    "        with tf.name_scope('clf_loss'):\n",
    "            loss1 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=logits1, labels=inputs['label'], name='nll'), 0, name='clf_loss1')\n",
    "\n",
    "#             loss2 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#                 logits=logits2, labels=inputs['sex'], name='nll'), 0, name='loss2')\n",
    "\n",
    "#             loss = loss1\n",
    "#             loss = loss1 + loss2\n",
    "\n",
    "        \n",
    "        ###\n",
    "        # Compute the logits and get the loss for decoder. \n",
    "        ###\n",
    "        logits_dec = conv1d(s, num_filters=256, filter_length=1, name='dec_logits')\n",
    "        logits_dec = tf.reshape(logits_dec, [-1, 256])\n",
    "        probs_dec = tf.nn.softmax(logits_dec, name='dec_softmax')\n",
    "        x_indices = tf.cast(tf.reshape(x_quantized, [-1]), tf.int32) + 128\n",
    "        loss_dec = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=logits_dec, labels=x_indices, name='nll'),\n",
    "            0,\n",
    "            name='dec_loss')\n",
    "        \n",
    "        loss = loss1 + loss_dec\n",
    "\n",
    "        return {'predictions_speaker' : logits1,\n",
    "#                 'predictions_sex' : logits2,\n",
    "                'loss': loss,\n",
    "                'eval': {'nll':loss}, \n",
    "                'quantized_input' : x_quantized,\n",
    "                'encoding':encoding,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOGDIR = \"/home/julia/DeepVoice_project/LOGDIR/\"\n",
    "OLD_MODEL_PATH = '/home/julia/DeepVoice_data/wavenet-ckpt/model.ckpt-200000'\n",
    "# OLD_MODEL_PATH = '/home/julia/DeepVoice_data/wavenet-voice-ckpt/model.ckpt-200000'\n",
    "\n",
    "# \"Batch size spread across all sync replicas.We use a size of 32.\"\n",
    "TOTAL_BATCH_SIZE = 1\n",
    "\n",
    "# \"Number of replicas. We train with 32.\"\n",
    "WORKER_REPLICAS = 1\n",
    "\n",
    "# \"Number of tasks in the ps job. If 0 no ps job is used. We typically use 11 \"\n",
    "PS_TASKS = 0\n",
    "\n",
    "wav_path = '/home/julia/DeepVoice_project/LibriSpeech_small'\n",
    "tfrecord_path = '{}/wavs.tfrecord'.format(wav_path)\n",
    "\n",
    "# \"The path to the train tfrecord\"\n",
    "TRAIN_PATH = tfrecord_path \n",
    "\n",
    "#  \"Task id of the replica running the training.\"\n",
    "TASK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get batch\n",
      "Lets get output\n",
      "INFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=1; total_num_replicas=1\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /home/julia/DeepVoice_project/LOGDIR/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    }
   ],
   "source": [
    "model = Config(train_path = TRAIN_PATH)   \n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    logdir = LOGDIR\n",
    "    total_batch_size = TOTAL_BATCH_SIZE\n",
    "    worker_replicas = WORKER_REPLICAS\n",
    "    assert total_batch_size % worker_replicas == 0\n",
    "    worker_batch_size = int(total_batch_size / worker_replicas)\n",
    "    \n",
    "    \n",
    "    # Run the Reader on the CPU\n",
    "    cpu_device = \"/job:localhost/replica:0/task:0/CPU:0\"\n",
    "    if PS_TASKS:\n",
    "        cpu_device = \"/job:worker/CPU:0\"\n",
    "        \n",
    "    # Get input batch for worker\n",
    "    with tf.device(cpu_device):\n",
    "        inputs_dict = model.get_batch(worker_batch_size)\n",
    "        \n",
    "    \n",
    "    with tf.device( tf.train.replica_device_setter(\n",
    "        ps_tasks=PS_TASKS, merge_devices=True)):\n",
    "        \n",
    "        global_step = tf.get_variable(\n",
    "            \"global_step\", [],\n",
    "            tf.int32,\n",
    "            initializer=tf.constant_initializer(0),\n",
    "            trainable=False)\n",
    "        \n",
    "        lr = model.learninig_rate\n",
    "        tf.summary.scalar(\"learning_rate\", lr)\n",
    "        \n",
    "        print('Lets get output')\n",
    "        outputs_dict = model.build(inputs_dict, is_training = True)\n",
    "        loss = outputs_dict[\"loss\"]\n",
    "        tf.summary.scalar(\"train_loss\", loss)\n",
    "        \n",
    "#         # if we don't want to use moving average while averaging gradients from replicas \n",
    "#         opt = tf.train.SyncReplicasOptimizer(\n",
    "#             tf.train.AdamOptimizer(lr, epsilon = 1e-8),\n",
    "#             replicas_to_aggregate = worker_replicas,\n",
    "#             total_num_replicas = worker_replicas)\n",
    "\n",
    "        # if we want to use moving average while averaging gradients from replicas \n",
    "        ema = tf.train.ExponentialMovingAverage(\n",
    "          decay=0.9999, num_updates=global_step)\n",
    "        opt = tf.train.SyncReplicasOptimizer(\n",
    "            tf.train.AdamOptimizer(lr, epsilon=1e-8),\n",
    "            replicas_to_aggregate = worker_replicas,\n",
    "            total_num_replicas=worker_replicas,\n",
    "            variable_averages=ema,\n",
    "            variables_to_average=tf.trainable_variables())\n",
    "\n",
    "        train_op = opt.minimize(\n",
    "            loss,\n",
    "            global_step = global_step,\n",
    "            name = \"train\",\n",
    "            colocate_gradients_with_ops = True)\n",
    "    \n",
    "        session_config = tf.ConfigProto(allow_soft_placement = True)\n",
    "        \n",
    "        ###\n",
    "        # Initialize ae layers with corresponding weights from pre-trained wavenet autoencoder\n",
    "        trainable_var_names = [v.op.name for v in tf.trainable_variables()]\n",
    "        \n",
    "        var_names_to_values = {}\n",
    "        reader = pywrap_tensorflow.NewCheckpointReader(OLD_MODEL_PATH) \n",
    "        \n",
    "        for key in np.intersect1d(trainable_var_names, list(reader.get_variable_to_shape_map().keys())):\n",
    "            var_names_to_values[key] = reader.get_tensor(key)\n",
    "\n",
    "        init_assign_op, init_feed_dict = slim.assign_from_values(var_names_to_values)\n",
    "        \n",
    "        def InitAssignFn(sess):\n",
    "            sess.run(init_assign_op, init_feed_dict)\n",
    "        ###\n",
    "        \n",
    "        is_chief = (TASK == 0)\n",
    "        local_init_op = opt.chief_init_op if is_chief else opt.local_step_init_op\n",
    "\n",
    "        slim.learning.train(\n",
    "            train_op=train_op,\n",
    "            is_chief=is_chief,\n",
    "            logdir = logdir,\n",
    "            number_of_steps=model.num_iters,\n",
    "            global_step=global_step,\n",
    "            log_every_n_steps=250,\n",
    "            local_init_op=local_init_op,\n",
    "            save_interval_secs=300,\n",
    "            sync_optimizer=opt,\n",
    "            session_config=session_config,\n",
    "            init_fn = InitAssignFn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/julia/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/julia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 0.4.0rc3 at http://julia-ThinkPad-T470:6006 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=/home/julia/DeepVoice_project/LOGDIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495 511\n",
      "496 496\n",
      "[[[[ True  True  True ...  True  True  True]\n",
      "   [ True  True  True ...  True  True  True]\n",
      "   [ True  True  True ...  True  True  True]\n",
      "   ...\n",
      "   [ True  True  True ...  True  True  True]\n",
      "   [ True  True  True ...  True  True  True]\n",
      "   [ True  True  True ...  True  True  True]]]]\n",
      "0 10\n",
      "[[False False False  True]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " ...\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]]\n",
      "0 10\n",
      "[[[[False False False ... False False False]\n",
      "   [False False False ... False False False]\n",
      "   [False False False ... False False False]\n",
      "   ...\n",
      "   [False False False ... False False False]\n",
      "   [False False False ... False False False]\n",
      "   [False False False ... False False False]]]]\n"
     ]
    }
   ],
   "source": [
    "reader = pywrap_tensorflow.NewCheckpointReader(OLD_MODEL_PATH)\n",
    "rdr1= pywrap_tensorflow.NewCheckpointReader(LOGDIR+'model.ckpt-0')\n",
    "rdr2= pywrap_tensorflow.NewCheckpointReader(LOGDIR+'model.ckpt-10')\n",
    "\n",
    "reader_keys = reader.get_variable_to_shape_map().keys()\n",
    "rdr_keys = rdr1.get_variable_to_shape_map().keys()\n",
    "print(len(reader_keys), len(rdr_keys))\n",
    "\n",
    "l = [key for key in reader_keys if key.startswith('ae')]\n",
    "ll = [key for key in rdr_keys if key.startswith('ae')]\n",
    "print(len(l), len(ll))\n",
    "\n",
    "# Lets show that we loaded weights from the old model correctly\n",
    "print(reader.get_tensor('ae_bottleneck/W') == rdr1.get_tensor('ae_bottleneck/W'))\n",
    "\n",
    "# Lets show that the weights change while training\n",
    "for key in ['fc1/W', 'ae_bottleneck/W']:\n",
    "    print(rdr1.get_tensor('global_step'), rdr2.get_tensor('global_step'))\n",
    "    print(rdr1.get_tensor(key) == rdr2.get_tensor(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beta1_power', 'beta2_power', 'fc1/B', 'fc1/B/Adam',\n",
       "       'fc1/B/Adam_1', 'fc1/B/ExponentialMovingAverage', 'fc1/W',\n",
       "       'fc1/W/Adam', 'fc1/W/Adam_1', 'fc1/W/ExponentialMovingAverage',\n",
       "       'fc2/B', 'fc2/B/ExponentialMovingAverage', 'fc2/W',\n",
       "       'fc2/W/ExponentialMovingAverage', 'global_step'], dtype='<U49')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setxor1d(list(rdr_keys), ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wav': <tf.Tensor 'Reshape_1:0' shape=(1, 39936) dtype=float32>, 'sr': <tf.Tensor 'strided_slice:0' shape=(1,) dtype=int32>, 'speaker': <tf.Tensor 'strided_slice_1:0' shape=(1,) dtype=int32>}\n",
      "{'predictions_speaker': <tf.Tensor 'fc1/add:0' shape=(1, 4) dtype=float32>, 'predictions_sex': <tf.Tensor 'fc2/add:0' shape=(1, 2) dtype=float32>, 'loss': <tf.Tensor 'loss/loss1:0' shape=() dtype=float32>, 'eval': {'nll': <tf.Tensor 'loss/loss1:0' shape=() dtype=float32>}, 'quantized_input': <tf.Tensor 'mu_law/Floor:0' shape=(1, 39936) dtype=float32>, 'encoding': <tf.Tensor 'ae_pool/Reshape_1:0' shape=(1, 78, 16) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(inputs_dict)\n",
    "print(outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ae_model(learning_rate, hparam):\n",
    "\n",
    "  \n",
    "    x = tf.placeholder(tf.float32, shape=[None,  1024*10], name=\"x\")\n",
    "    labels1 = tf.placeholder(tf.int32, shape = [None], name = 'labels1')\n",
    "    labels2 = tf.placeholder(tf.int32, shape = [None], name = 'labels2')\n",
    "    \n",
    "    print('x initial shape: {}'.format(x.get_shape().as_list()))\n",
    "\n",
    "    x_quantized = mu_law(x)\n",
    "    with tf.name_scope(\"scale_and_expand_dims\"):\n",
    "        x_scaled = tf.cast(x_quantized, tf.float32) / 128.0\n",
    "        x_scaled = tf.expand_dims(x_scaled, 2)\n",
    "\n",
    "    print('x converted')\n",
    "    print('x scaled shape: {}'.format(x_scaled.get_shape().as_list()))\n",
    "\n",
    "    LOGDIR = \"/home/julia/DeepVoice_project/LOGDIR/\"\n",
    "    CHECKPOINT = '/home/julia/magenta-demos/jupyter-notebooks/wavenet-ckpt/model.ckpt-200000'\n",
    "\n",
    "\n",
    "    ae_filter_length = 3\n",
    "    ae_width = 128\n",
    "    ae_bottleneck_width = 16\n",
    "    ae_hop_length = 512\n",
    "\n",
    "\n",
    "    en = conv1d(x_scaled,\n",
    "                causal=False,\n",
    "                num_filters=ae_width,\n",
    "                filter_length=ae_filter_length, dilation = 1,\n",
    "                name='ae_startconv')\n",
    "\n",
    "    ae_num_layers = 30\n",
    "    ae_num_stages = 10\n",
    "    for num_layer in range(ae_num_layers):\n",
    "        with tf.name_scope('layer_{}'.format(num_layer)):\n",
    "            dilation = 2**(num_layer % ae_num_stages)\n",
    "\n",
    "            d = tf.nn.relu(en)\n",
    "            d = conv1d(d,\n",
    "                       causal=False,\n",
    "                       num_filters=ae_width,\n",
    "                       filter_length=ae_filter_length,\n",
    "                       dilation=dilation,\n",
    "                       name='ae_dilatedconv_%d' % (num_layer + 1))\n",
    "            d = tf.nn.relu(d)\n",
    "            en += conv1d(d,\n",
    "                         num_filters=ae_width,\n",
    "                         filter_length=1,\n",
    "                         name='ae_res_%d' % (num_layer + 1))\n",
    "\n",
    "    en = conv1d(en,\n",
    "                num_filters=ae_bottleneck_width,\n",
    "                filter_length=1,\n",
    "                name='ae_bottleneck')\n",
    "    en = pool1d(en, ae_hop_length, name = 'ae_pool', mode = 'avg')\n",
    "\n",
    "    en_shape = en.get_shape().as_list()\n",
    "    flattened = tf.reshape(en, [-1, en_shape[-1]*en_shape[-2]])\n",
    "    \n",
    "#     embedding_input = fc_layer(flattened,  en_shape[-1]*en_shape[-2], 6, \"fc\")\n",
    "#     embedding_size = 6\n",
    "\n",
    "\n",
    "    logits1 = fc_layer(flattened,  en_shape[-1]*en_shape[-2], 4, \"fc1\")\n",
    "    probs1 = tf.nn.softmax(logits1, name = 'softmax1')\n",
    "\n",
    "    logits2 = fc_layer(flattened,  en_shape[-1]*en_shape[-2], 2, \"fc2\")\n",
    "    probs2 = tf.nn.softmax(logits2, name = 'softmax2')\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss1 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits1, labels=labels1, name='nll'), 0, name='loss1')\n",
    "\n",
    "        loss2 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits2, labels=labels2, name='nll'), 0, name='loss2')\n",
    "        \n",
    "        loss = loss1\n",
    "        loss = loss1 + loss2\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "#     with tf.name_scope(\"train\"):\n",
    "#         train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "    \n",
    "#     embedding = tf.Variable(tf.zeros([10, embedding_size]), name = 'test_embedding')\n",
    "#     assignment = embedding.assign(embedding_input)\n",
    "#     print(embedding_input.shape)\n",
    "    \n",
    "    \n",
    "    MODEL_PATH = '/home/julia/magenta-demos/jupyter-notebooks/wavenet-ckpt/model.ckpt-200000'\n",
    "#     MODEL_PATH = \"/home/julia/DeepVoice_project/LOGDIR/model.ckpt-2\"    \n",
    "    \n",
    "    all_variables = tf.global_variables()\n",
    "    \n",
    "    saver = tf.train.Saver(all_variables[:1])\n",
    "#     saver = tf.train.Saver()\n",
    "   \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        tf.variables_initializer(all_variables[1:]).run()\n",
    "        saver.restore(sess, MODEL_PATH)\n",
    "\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "        writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "        writer.add_graph(sess.graph)\n",
    "\n",
    "\n",
    "    #     config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    #     embedding_config = config.embeddings.add()\n",
    "    #     embedding_config.tensor_name = embedding.name\n",
    "    #     LABELS = os.path.join(os.getcwd(), \"labels_10.tsv\")\n",
    "\n",
    "    #     embedding_config.metadata_path = LABELS\n",
    "    #     tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)   \n",
    "\n",
    "#         for i in range(3):\n",
    "#             print('\\n________________Step {}________________'.format(i))\n",
    "\n",
    "\n",
    "#             batch = [np.zeros((10, 1024*10)),\n",
    "#                      np.random.choice(np.arange(4), size = 10),\n",
    "#                      np.random.choice(np.arange(2), size = 10)]\n",
    "# #             if i%1 == 0:\n",
    "#     # #             print('\\n________________Step {}________________'.format(i))\n",
    "#     #             [s] = sess.run([summ], feed_dict = {x: batch[0], labels1: batch[1], labels2: batch[2]})\n",
    "#     #             writer.add_summary(s, i)\n",
    "#             if i%2 == 0:\n",
    "# #                 sess.run(assignment, feed_dict={x: batch[0], labels1: batch[1], labels2: batch[2]})\n",
    "\n",
    "#                 saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "\n",
    "#             sess.run(train_step, feed_dict = {x: batch[0],  labels1: batch[1], labels2: batch[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for ae\n",
      "x initial shape: [None, 10240]\n",
      "x converted\n",
      "x scaled shape: [None, 10240, 1]\n",
      "\n",
      "_______ae_startconv_______\n",
      "\n",
      "_______ae_dilatedconv_1_______\n",
      "\n",
      "_______ae_res_1_______\n",
      "\n",
      "_______ae_dilatedconv_2_______\n",
      "\n",
      "_______ae_res_2_______\n",
      "\n",
      "_______ae_dilatedconv_3_______\n",
      "\n",
      "_______ae_res_3_______\n",
      "\n",
      "_______ae_dilatedconv_4_______\n",
      "\n",
      "_______ae_res_4_______\n",
      "\n",
      "_______ae_dilatedconv_5_______\n",
      "\n",
      "_______ae_res_5_______\n",
      "\n",
      "_______ae_dilatedconv_6_______\n",
      "\n",
      "_______ae_res_6_______\n",
      "\n",
      "_______ae_dilatedconv_7_______\n",
      "\n",
      "_______ae_res_7_______\n",
      "\n",
      "_______ae_dilatedconv_8_______\n",
      "\n",
      "_______ae_res_8_______\n",
      "\n",
      "_______ae_dilatedconv_9_______\n",
      "\n",
      "_______ae_res_9_______\n",
      "\n",
      "_______ae_dilatedconv_10_______\n",
      "\n",
      "_______ae_res_10_______\n",
      "\n",
      "_______ae_dilatedconv_11_______\n",
      "\n",
      "_______ae_res_11_______\n",
      "\n",
      "_______ae_dilatedconv_12_______\n",
      "\n",
      "_______ae_res_12_______\n",
      "\n",
      "_______ae_dilatedconv_13_______\n",
      "\n",
      "_______ae_res_13_______\n",
      "\n",
      "_______ae_dilatedconv_14_______\n",
      "\n",
      "_______ae_res_14_______\n",
      "\n",
      "_______ae_dilatedconv_15_______\n",
      "\n",
      "_______ae_res_15_______\n",
      "\n",
      "_______ae_dilatedconv_16_______\n",
      "\n",
      "_______ae_res_16_______\n",
      "\n",
      "_______ae_dilatedconv_17_______\n",
      "\n",
      "_______ae_res_17_______\n",
      "\n",
      "_______ae_dilatedconv_18_______\n",
      "\n",
      "_______ae_res_18_______\n",
      "\n",
      "_______ae_dilatedconv_19_______\n",
      "\n",
      "_______ae_res_19_______\n",
      "\n",
      "_______ae_dilatedconv_20_______\n",
      "\n",
      "_______ae_res_20_______\n",
      "\n",
      "_______ae_dilatedconv_21_______\n",
      "\n",
      "_______ae_res_21_______\n",
      "\n",
      "_______ae_dilatedconv_22_______\n",
      "\n",
      "_______ae_res_22_______\n",
      "\n",
      "_______ae_dilatedconv_23_______\n",
      "\n",
      "_______ae_res_23_______\n",
      "\n",
      "_______ae_dilatedconv_24_______\n",
      "\n",
      "_______ae_res_24_______\n",
      "\n",
      "_______ae_dilatedconv_25_______\n",
      "\n",
      "_______ae_res_25_______\n",
      "\n",
      "_______ae_dilatedconv_26_______\n",
      "\n",
      "_______ae_res_26_______\n",
      "\n",
      "_______ae_dilatedconv_27_______\n",
      "\n",
      "_______ae_res_27_______\n",
      "\n",
      "_______ae_dilatedconv_28_______\n",
      "\n",
      "_______ae_res_28_______\n",
      "\n",
      "_______ae_dilatedconv_29_______\n",
      "\n",
      "_______ae_res_29_______\n",
      "\n",
      "_______ae_dilatedconv_30_______\n",
      "\n",
      "_______ae_res_30_______\n",
      "\n",
      "_______ae_bottleneck_______\n",
      "\n",
      "_______ae_pool_______\n",
      "INFO:tensorflow:Restoring parameters from /home/julia/magenta-demos/jupyter-notebooks/wavenet-ckpt/model.ckpt-200000\n"
     ]
    }
   ],
   "source": [
    "hparam = 'ae'\n",
    "\n",
    "print('Starting run for %s' % hparam)\n",
    "tf.reset_default_graph()\n",
    "ae_model(1e-3, hparam)\n",
    "# print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae_bottleneck/W (DT_FLOAT) [1,1,128,16]\n",
      "ae_bottleneck/W/Adam (DT_FLOAT) [1,1,128,16]\n",
      "ae_bottleneck/W/Adam_1 (DT_FLOAT) [1,1,128,16]\n",
      "ae_bottleneck/biases (DT_FLOAT) [16]\n",
      "ae_bottleneck/biases/Adam (DT_FLOAT) [16]\n",
      "ae_bottleneck/biases/Adam_1 (DT_FLOAT) [16]\n",
      "ae_dilatedconv_1/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_1/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_1/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_1/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_1/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_1/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_10/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_10/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_10/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_10/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_10/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_10/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_11/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_11/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_11/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_11/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_11/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_11/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_12/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_12/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_12/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_12/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_12/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_12/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_13/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_13/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_13/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_13/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_13/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_13/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_14/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_14/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_14/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_14/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_14/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_14/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_15/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_15/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_15/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_15/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_15/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_15/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_16/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_16/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_16/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_16/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_16/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_16/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_17/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_17/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_17/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_17/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_17/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_17/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_18/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_18/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_18/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_18/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_18/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_18/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_19/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_19/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_19/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_19/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_19/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_19/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_2/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_2/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_2/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_2/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_2/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_2/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_20/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_20/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_20/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_20/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_20/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_20/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_21/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_21/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_21/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_21/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_21/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_21/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_22/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_22/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_22/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_22/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_22/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_22/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_23/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_23/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_23/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_23/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_23/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_23/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_24/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_24/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_24/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_24/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_24/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_24/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_25/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_25/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_25/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_25/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_25/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_25/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_26/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_26/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_26/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_26/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_26/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_26/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_27/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_27/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_27/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_27/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_27/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_27/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_28/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_28/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_28/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_28/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_28/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_28/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_29/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_29/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_29/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_29/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_29/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_29/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_3/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_3/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_3/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_3/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_3/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_3/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_30/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_30/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_30/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_30/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_30/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_30/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_4/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_4/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_4/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_4/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_4/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_4/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_5/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_5/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_5/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_5/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_5/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_5/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_6/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_6/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_6/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_6/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_6/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_6/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_7/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_7/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_7/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_7/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_7/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_7/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_8/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_8/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_8/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_8/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_8/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_8/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_dilatedconv_9/W (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_9/W/Adam (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_9/W/Adam_1 (DT_FLOAT) [1,3,128,128]\n",
      "ae_dilatedconv_9/biases (DT_FLOAT) [128]\n",
      "ae_dilatedconv_9/biases/Adam (DT_FLOAT) [128]\n",
      "ae_dilatedconv_9/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_1/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_1/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_1/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_1/biases (DT_FLOAT) [128]\n",
      "ae_res_1/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_1/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_10/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_10/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_10/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_10/biases (DT_FLOAT) [128]\n",
      "ae_res_10/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_10/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_11/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_11/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_11/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_11/biases (DT_FLOAT) [128]\n",
      "ae_res_11/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_11/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_12/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_12/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_12/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_12/biases (DT_FLOAT) [128]\n",
      "ae_res_12/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_12/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_13/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_13/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_13/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_13/biases (DT_FLOAT) [128]\n",
      "ae_res_13/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_13/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_14/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_14/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_14/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_14/biases (DT_FLOAT) [128]\n",
      "ae_res_14/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_14/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_15/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_15/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_15/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_15/biases (DT_FLOAT) [128]\n",
      "ae_res_15/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_15/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_16/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_16/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_16/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_16/biases (DT_FLOAT) [128]\n",
      "ae_res_16/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_16/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_17/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_17/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_17/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_17/biases (DT_FLOAT) [128]\n",
      "ae_res_17/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_17/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_18/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_18/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_18/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_18/biases (DT_FLOAT) [128]\n",
      "ae_res_18/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_18/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_19/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_19/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_19/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_19/biases (DT_FLOAT) [128]\n",
      "ae_res_19/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_19/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_2/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_2/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_2/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_2/biases (DT_FLOAT) [128]\n",
      "ae_res_2/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_2/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_20/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_20/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_20/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_20/biases (DT_FLOAT) [128]\n",
      "ae_res_20/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_20/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_21/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_21/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_21/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_21/biases (DT_FLOAT) [128]\n",
      "ae_res_21/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_21/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_22/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_22/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_22/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_22/biases (DT_FLOAT) [128]\n",
      "ae_res_22/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_22/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_23/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_23/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_23/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_23/biases (DT_FLOAT) [128]\n",
      "ae_res_23/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_23/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_24/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_24/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_24/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_24/biases (DT_FLOAT) [128]\n",
      "ae_res_24/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_24/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_25/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_25/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_25/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_25/biases (DT_FLOAT) [128]\n",
      "ae_res_25/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_25/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_26/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_26/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_26/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_26/biases (DT_FLOAT) [128]\n",
      "ae_res_26/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_26/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_27/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_27/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_27/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_27/biases (DT_FLOAT) [128]\n",
      "ae_res_27/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_27/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_28/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_28/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_28/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_28/biases (DT_FLOAT) [128]\n",
      "ae_res_28/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_28/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_29/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_29/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_29/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_29/biases (DT_FLOAT) [128]\n",
      "ae_res_29/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_29/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_3/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_3/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_3/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_3/biases (DT_FLOAT) [128]\n",
      "ae_res_3/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_3/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_30/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_30/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_30/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_30/biases (DT_FLOAT) [128]\n",
      "ae_res_30/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_30/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_4/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_4/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_4/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_4/biases (DT_FLOAT) [128]\n",
      "ae_res_4/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_4/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_5/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_5/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_5/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_5/biases (DT_FLOAT) [128]\n",
      "ae_res_5/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_5/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_6/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_6/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_6/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_6/biases (DT_FLOAT) [128]\n",
      "ae_res_6/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_6/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_7/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_7/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_7/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_7/biases (DT_FLOAT) [128]\n",
      "ae_res_7/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_7/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_8/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_8/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_8/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_8/biases (DT_FLOAT) [128]\n",
      "ae_res_8/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_8/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_res_9/W (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_9/W/Adam (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_9/W/Adam_1 (DT_FLOAT) [1,1,128,128]\n",
      "ae_res_9/biases (DT_FLOAT) [128]\n",
      "ae_res_9/biases/Adam (DT_FLOAT) [128]\n",
      "ae_res_9/biases/Adam_1 (DT_FLOAT) [128]\n",
      "ae_startconv/W (DT_FLOAT) [1,3,1,128]\n",
      "ae_startconv/W/Adam (DT_FLOAT) [1,3,1,128]\n",
      "ae_startconv/W/Adam_1 (DT_FLOAT) [1,3,1,128]\n",
      "ae_startconv/biases (DT_FLOAT) [128]\n",
      "ae_startconv/biases/Adam (DT_FLOAT) [128]\n",
      "ae_startconv/biases/Adam_1 (DT_FLOAT) [128]\n",
      "fc/B (DT_FLOAT) [4]\n",
      "fc/B/Adam (DT_FLOAT) [4]\n",
      "fc/B/Adam_1 (DT_FLOAT) [4]\n",
      "fc/W (DT_FLOAT) [320,4]\n",
      "fc/W/Adam (DT_FLOAT) [320,4]\n",
      "fc/W/Adam_1 (DT_FLOAT) [320,4]\n",
      "fc_1/B (DT_FLOAT) [2]\n",
      "fc_1/B/Adam (DT_FLOAT) [2]\n",
      "fc_1/B/Adam_1 (DT_FLOAT) [2]\n",
      "fc_1/W (DT_FLOAT) [320,2]\n",
      "fc_1/W/Adam (DT_FLOAT) [320,2]\n",
      "fc_1/W/Adam_1 (DT_FLOAT) [320,2]\n",
      "train/beta1_power (DT_FLOAT) []\n",
      "train/beta2_power (DT_FLOAT) []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "MODEL_PATH = \"/home/julia/DeepVoice_project/LOGDIR/model.ckpt-2\"\n",
    "print_tensors_in_checkpoint_file(file_name=MODEL_PATH, tensor_name='', all_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ae_bottleneck/W', 'ae_bottleneck/biases', 'ae_dilatedconv_1/W',\n",
       "       'ae_dilatedconv_1/biases', 'ae_dilatedconv_10/W',\n",
       "       'ae_dilatedconv_10/biases', 'ae_dilatedconv_11/W',\n",
       "       'ae_dilatedconv_11/biases', 'ae_dilatedconv_12/W',\n",
       "       'ae_dilatedconv_12/biases', 'ae_dilatedconv_13/W',\n",
       "       'ae_dilatedconv_13/biases', 'ae_dilatedconv_14/W',\n",
       "       'ae_dilatedconv_14/biases', 'ae_dilatedconv_15/W',\n",
       "       'ae_dilatedconv_15/biases', 'ae_dilatedconv_16/W',\n",
       "       'ae_dilatedconv_16/biases', 'ae_dilatedconv_17/W',\n",
       "       'ae_dilatedconv_17/biases', 'ae_dilatedconv_18/W',\n",
       "       'ae_dilatedconv_18/biases', 'ae_dilatedconv_19/W',\n",
       "       'ae_dilatedconv_19/biases', 'ae_dilatedconv_2/W',\n",
       "       'ae_dilatedconv_2/biases', 'ae_dilatedconv_20/W',\n",
       "       'ae_dilatedconv_20/biases', 'ae_dilatedconv_21/W',\n",
       "       'ae_dilatedconv_21/biases', 'ae_dilatedconv_22/W',\n",
       "       'ae_dilatedconv_22/biases', 'ae_dilatedconv_23/W',\n",
       "       'ae_dilatedconv_23/biases', 'ae_dilatedconv_24/W',\n",
       "       'ae_dilatedconv_24/biases', 'ae_dilatedconv_25/W',\n",
       "       'ae_dilatedconv_25/biases', 'ae_dilatedconv_26/W',\n",
       "       'ae_dilatedconv_26/biases', 'ae_dilatedconv_27/W',\n",
       "       'ae_dilatedconv_27/biases', 'ae_dilatedconv_28/W',\n",
       "       'ae_dilatedconv_28/biases', 'ae_dilatedconv_29/W',\n",
       "       'ae_dilatedconv_29/biases', 'ae_dilatedconv_3/W',\n",
       "       'ae_dilatedconv_3/biases', 'ae_dilatedconv_30/W',\n",
       "       'ae_dilatedconv_30/biases', 'ae_dilatedconv_4/W',\n",
       "       'ae_dilatedconv_4/biases', 'ae_dilatedconv_5/W',\n",
       "       'ae_dilatedconv_5/biases', 'ae_dilatedconv_6/W',\n",
       "       'ae_dilatedconv_6/biases', 'ae_dilatedconv_7/W',\n",
       "       'ae_dilatedconv_7/biases', 'ae_dilatedconv_8/W',\n",
       "       'ae_dilatedconv_8/biases', 'ae_dilatedconv_9/W',\n",
       "       'ae_dilatedconv_9/biases', 'ae_res_1/W', 'ae_res_1/biases',\n",
       "       'ae_res_10/W', 'ae_res_10/biases', 'ae_res_11/W',\n",
       "       'ae_res_11/biases', 'ae_res_12/W', 'ae_res_12/biases',\n",
       "       'ae_res_13/W', 'ae_res_13/biases', 'ae_res_14/W',\n",
       "       'ae_res_14/biases', 'ae_res_15/W', 'ae_res_15/biases',\n",
       "       'ae_res_16/W', 'ae_res_16/biases', 'ae_res_17/W',\n",
       "       'ae_res_17/biases', 'ae_res_18/W', 'ae_res_18/biases',\n",
       "       'ae_res_19/W', 'ae_res_19/biases', 'ae_res_2/W', 'ae_res_2/biases',\n",
       "       'ae_res_20/W', 'ae_res_20/biases', 'ae_res_21/W',\n",
       "       'ae_res_21/biases', 'ae_res_22/W', 'ae_res_22/biases',\n",
       "       'ae_res_23/W', 'ae_res_23/biases', 'ae_res_24/W',\n",
       "       'ae_res_24/biases', 'ae_res_25/W', 'ae_res_25/biases',\n",
       "       'ae_res_26/W', 'ae_res_26/biases', 'ae_res_27/W',\n",
       "       'ae_res_27/biases', 'ae_res_28/W', 'ae_res_28/biases',\n",
       "       'ae_res_29/W', 'ae_res_29/biases', 'ae_res_3/W', 'ae_res_3/biases',\n",
       "       'ae_res_30/W', 'ae_res_30/biases', 'ae_res_4/W', 'ae_res_4/biases',\n",
       "       'ae_res_5/W', 'ae_res_5/biases', 'ae_res_6/W', 'ae_res_6/biases',\n",
       "       'ae_res_7/W', 'ae_res_7/biases', 'ae_res_8/W', 'ae_res_8/biases',\n",
       "       'ae_res_9/W', 'ae_res_9/biases', 'ae_startconv/W',\n",
       "       'ae_startconv/biases'], dtype='<U49')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(varlist, old_varlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae_startconv/W: [1, 3, 1, 128]\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/home/julia/DeepVoice_project/LOGDIR/model.ckpt-2\"    \n",
    "\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(MODEL_PATH)\n",
    "\n",
    "var_to_shape_map  = reader.get_variable_to_shape_map()\n",
    "for key,value in sorted(var_to_shape_map.items()):\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_layers = [key for key in var_to_shape_map.keys() if key.startswith('ae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae_startconv/biases', 'ae_startconv/W/Adam_1', 'ae_startconv/W']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_layers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.01203278, -0.10520291,  0.12341633, -0.09523151,\n",
       "           0.09587987, -0.02144042,  0.0783055 , -0.02178621,\n",
       "          -0.01088013, -0.0614558 , -0.07129394, -0.00432002,\n",
       "           0.08259791, -0.10954858, -0.11433904, -0.09195298,\n",
       "          -0.02012742, -0.10045623,  0.09914373,  0.07430148,\n",
       "           0.04196946,  0.12193274,  0.05003662, -0.08656662,\n",
       "           0.01942925, -0.11667161, -0.12117441, -0.07204361,\n",
       "           0.08887656, -0.11284521, -0.02322815, -0.09519912,\n",
       "           0.10204411,  0.12054746, -0.06709029,  0.02591731,\n",
       "          -0.00541955, -0.04868354, -0.11747795, -0.1067972 ,\n",
       "          -0.05294297, -0.0428362 , -0.017465  ,  0.00290056,\n",
       "          -0.01198498,  0.07556932,  0.10766061,  0.06721687,\n",
       "          -0.10235035, -0.04098432,  0.00133857, -0.01291195,\n",
       "           0.01132475,  0.12098466,  0.06837414,  0.0697061 ,\n",
       "          -0.09864458,  0.08200732,  0.02888057, -0.11723948,\n",
       "           0.07483652, -0.05749021,  0.03027664, -0.0310448 ,\n",
       "           0.11965653, -0.0800233 ,  0.04850993,  0.10121781,\n",
       "           0.04543494, -0.02423803,  0.05893874, -0.01597682,\n",
       "           0.10917011, -0.10254335, -0.10876331, -0.04156271,\n",
       "           0.04697245,  0.02273291,  0.01756489, -0.1052762 ,\n",
       "          -0.07427165, -0.03061809, -0.06669703, -0.04186218,\n",
       "          -0.00462769,  0.11735594, -0.10298009, -0.02306057,\n",
       "           0.0035854 ,  0.12175807,  0.00617371,  0.01420307,\n",
       "          -0.07197658,  0.00054674, -0.08745074,  0.12275808,\n",
       "          -0.07116222, -0.04991345,  0.09671156,  0.08967797,\n",
       "           0.06290771, -0.0464227 ,  0.09953022,  0.05693483,\n",
       "           0.0282979 , -0.05688576, -0.11966434,  0.1187418 ,\n",
       "          -0.01253062, -0.0036654 , -0.07155082,  0.07394005,\n",
       "          -0.02999877,  0.01142904, -0.10854348, -0.12337727,\n",
       "          -0.03102284, -0.11434919, -0.10205019, -0.00589287,\n",
       "           0.05466889,  0.10855734, -0.06880044,  0.10692371,\n",
       "          -0.02108418,  0.07737903,  0.03333287,  0.01570632]],\n",
       "\n",
       "        [[-0.07439066, -0.03369968,  0.08368452, -0.07287389,\n",
       "          -0.11933458, -0.10687286,  0.03197035,  0.03842305,\n",
       "          -0.02369141, -0.06159159, -0.08641198,  0.05506989,\n",
       "           0.04580946, -0.09231323, -0.02990894, -0.0686716 ,\n",
       "          -0.04119563, -0.0455291 , -0.10276897, -0.04545633,\n",
       "           0.04885907, -0.09113613,  0.10683608,  0.09376313,\n",
       "          -0.06734517, -0.08969077, -0.10708886,  0.10690507,\n",
       "          -0.05306415, -0.08766876, -0.02802957,  0.0495754 ,\n",
       "          -0.06669477,  0.00221442, -0.07956177, -0.0213275 ,\n",
       "          -0.1023917 ,  0.00513344, -0.0460976 ,  0.07281798,\n",
       "           0.08084688, -0.10516612,  0.03382249, -0.05788222,\n",
       "           0.01931131, -0.04768761, -0.11236744, -0.09327887,\n",
       "           0.06316046,  0.10818961,  0.01079012,  0.06769025,\n",
       "           0.04609454,  0.04316679, -0.06619447, -0.02812329,\n",
       "          -0.10810059, -0.03627262, -0.10263163, -0.12287726,\n",
       "          -0.01804799, -0.10725176,  0.11667089,  0.07796   ,\n",
       "          -0.0143944 ,  0.04160513, -0.09224593,  0.11674158,\n",
       "           0.00579616, -0.11755748, -0.0414043 ,  0.04727292,\n",
       "           0.00313327, -0.10006585, -0.08340432, -0.04697487,\n",
       "          -0.12185815, -0.11947645, -0.0093348 ,  0.01159306,\n",
       "           0.01593128, -0.1113244 , -0.08298134, -0.04846   ,\n",
       "          -0.08172147, -0.11876994, -0.11438951, -0.01241986,\n",
       "          -0.00335975,  0.12021737,  0.05250713, -0.00342482,\n",
       "          -0.08268839, -0.06665766, -0.04480202, -0.05387658,\n",
       "           0.04179949, -0.03374216,  0.09969088,  0.08346859,\n",
       "           0.10500716, -0.07004197, -0.06589481, -0.06314838,\n",
       "          -0.09596346,  0.05392212,  0.04752795,  0.10931355,\n",
       "           0.03817771, -0.10448814, -0.12003426,  0.01955055,\n",
       "          -0.10309573, -0.05530421, -0.05309986, -0.03414373,\n",
       "           0.08021227,  0.03560108, -0.03741439, -0.06409547,\n",
       "          -0.08262227, -0.10599744, -0.1082812 ,  0.05501868,\n",
       "          -0.07666855,  0.02355672, -0.00797717, -0.08735174]],\n",
       "\n",
       "        [[ 0.0703377 ,  0.04069333,  0.04425605, -0.08397435,\n",
       "          -0.0990905 , -0.06711899, -0.11149415,  0.08739392,\n",
       "           0.05956231, -0.0723042 , -0.02669863,  0.09252685,\n",
       "          -0.02869372, -0.08628851,  0.02299099, -0.08123684,\n",
       "          -0.01869614, -0.01251361,  0.02241254, -0.06373329,\n",
       "          -0.09821053, -0.04140106, -0.00619859, -0.00563054,\n",
       "          -0.10737306, -0.00900323, -0.08148484, -0.03566475,\n",
       "           0.03106128,  0.04411744,  0.09353168,  0.06496981,\n",
       "          -0.11875103,  0.07048103, -0.04354315, -0.05566241,\n",
       "          -0.04793911,  0.01109646, -0.02674803,  0.02678071,\n",
       "           0.0295193 ,  0.09092757,  0.02192186,  0.06935979,\n",
       "           0.05075459, -0.06023043,  0.10088716, -0.12194513,\n",
       "          -0.01676476, -0.11836921,  0.01140496, -0.0448231 ,\n",
       "           0.00519016, -0.06238315, -0.05345396, -0.10402257,\n",
       "           0.10289739,  0.01939587,  0.04009129,  0.11151361,\n",
       "           0.01396546, -0.0514323 , -0.10346894,  0.02562496,\n",
       "           0.0763386 , -0.07646071, -0.06150345,  0.08182365,\n",
       "          -0.06365035, -0.01992653,  0.07190551,  0.09924692,\n",
       "          -0.05300133, -0.03903946, -0.06356126, -0.03601229,\n",
       "           0.08172067, -0.01357778,  0.03677818,  0.07103854,\n",
       "          -0.02808954,  0.06271832, -0.10795111, -0.09552033,\n",
       "          -0.01522031,  0.09196299,  0.099949  , -0.06199114,\n",
       "          -0.08162475, -0.03955203,  0.09291996, -0.01704841,\n",
       "          -0.08371507,  0.02414846,  0.07209612, -0.07650251,\n",
       "          -0.05792437, -0.12318956,  0.06015776,  0.07135646,\n",
       "          -0.01758233, -0.00366852,  0.05256337,  0.11779608,\n",
       "           0.08486263,  0.11812782, -0.08198699, -0.07945903,\n",
       "           0.09012143,  0.02416576, -0.02168813, -0.11680339,\n",
       "           0.07800987,  0.09389164, -0.06149324,  0.00677033,\n",
       "           0.04194178,  0.081991  ,  0.0823008 , -0.01564735,\n",
       "           0.09595649,  0.03727961,  0.07572077, -0.0812714 ,\n",
       "          -0.0663325 , -0.11070068, -0.06080873,  0.01918347]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.get_tensor(ae_layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/julia/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/julia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 0.4.0rc3 at http://julia-ThinkPad-T470:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=/home/julia/DeepVoice_project/LOGDIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array({0: 1, 1: 2, 2: 4, 3: 8, 4: 1, 5: 2, 6: 4, 7: 8}, dtype=object)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def foo(num_l, num_s):\n",
    "#     print(num_l, num_s)\n",
    "    res = {}\n",
    "    for l in range(num_l):\n",
    "        d = 2**(l%num_s)\n",
    "#         print('\\t {}: {}'.format(l, d))\n",
    "        res.update({l: d})\n",
    "    return np.array(res)\n",
    "\n",
    "# for num_l in range(1, 8):\n",
    "#     for num_s in range(1, 8):\n",
    "#         foo(num_l, num_s)\n",
    "# df = pd.DataFrame(columns = ['num_layers', 'num_stages'])\n",
    "df = {(num_l, num_s): foo(num_l, num_s) for num_l in range(8, 9) for num_s in range(4, 5)}\n",
    "df = pd.DataFrame.from_dict(df, orient = 'index')\n",
    "df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.Variable(tf.ones((1, 2)), name = 'slit')\n",
    "y = tf.Variable(tf.ones((1, 2)), name = 'slit2')\n",
    "z = tf.Variable(tf.ones((1, 2)), name = 'slit3')\n",
    "s = tf.Variable(tf.ones((1, 2)), name = 'pslit')\n",
    "t = tf.Variable(tf.ones((1, 2)), name = 'pslit2')\n",
    "\n",
    "varlist = tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pslit', 'pslit2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.op.name for v in varlist if not v.name.startswith('s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
